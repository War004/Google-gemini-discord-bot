{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvBoob1J1HiZ"
      },
      "source": [
        "# Know Error\n",
        "üü© The bot tends to genrate multiple responese for a single reply (fixed)\n",
        "\n",
        "üü© Genrates multiple responses while working with media files (fixed)\n",
        "\n",
        "üü© Is able to remember images only time it is uploaded.(fixed)\n",
        "\n",
        "üü© Improving the video responses(Direct function added by google for video file)\n",
        "\n",
        "üü© Finding a way to keep the converstion for the videos conversation\n",
        "\n",
        "üü© If the user sends a gif through the inbuilt gif section, it's html page is downloaded.(fixed)\n",
        "\n",
        "[The gif is converted to a mp4 file. If your gif is shorter then it will treat it as a still photo as gemini sees videos with one frame per seconds, which might lead to wrong interpretation of the gif]\n",
        "\n",
        "üü© Gifs from the discord keyboard(tenor), doesn't get interpretted correct(because different gifs get donwloaded) (fixed)\n",
        "\n",
        " !check_token doesn't  work for direct messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rJKqNdtYq1g"
      },
      "source": [
        "# Goal\n",
        "1. Fix the 2000 char limit. ‚úÖ\n",
        "2. Saving the chats. ‚úÖ\n",
        "3. Only reply when tagged or replied ‚úÖ\n",
        "4. Consinent chats ‚úÖ\n",
        "5. Image input ‚úÖ\n",
        "6. Mutimedia input ‚úÖ\n",
        "7. Webhook ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "# d_bot\n",
        "This notebook lets you run a discord bot powered by google gemini api, with conversation memory which includes audio, video, and images.\n",
        "\n",
        "You can type **\"!check_token\"** to check how many tokens are being used.\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1OQGPc2CsYpnBhNfKEl0O0cDT6uXAcQ8g?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "nggWQnMA9EEl",
        "outputId": "88603b74-3ded-48a3-95b5-b677bd759b89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then start block below (Uses only 13MB of data)</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title <b>v-- If you play on mobile, tap this to open music player and play the white noise to keep tab running in the background. or your session might get disconnected\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start block below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X69TeVJU4cmw",
        "outputId": "8efe2f27-0ac9-48ab-af8f-624a810c9b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Mount your google drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFKN43bICGME"
      },
      "source": [
        "# Step 1: Install requirments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma-s35dvLHdk",
        "outputId": "f110f687-e68c-433b-e3e8-0f0e98d417ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install Discord\n",
        "!pip install python-magic\n",
        "!pip install nest_asyncio\n",
        "!pip install moviepy\n",
        "!pip install pytz\n",
        "clear_output()\n",
        "print(\"Success\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goraCIaRXzoe"
      },
      "source": [
        "Step 2: Get the api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5mUqu8_KXuzu"
      },
      "outputs": [],
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "C4BCsz3XX__W",
        "outputId": "1627a712-3ddc-4614-88a7-db0551268159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "Now select any one of the model and paste it in the 'model_name' below\n"
          ]
        }
      ],
      "source": [
        "# @title Step 2.5: List available models\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "print(\"Now select any one of the model and paste it in the 'model_name' below\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "wHUdpD-u1JAm"
      },
      "outputs": [],
      "source": [
        "# Set the event listener for the dropdown change\n",
        "# @title Model configuration\n",
        "text_generation_config = {\n",
        "    \"temperature\": 1.35,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "# Initial prompt\n",
        "system_instruction = \"Remember that you have the power of python to solve logical question if possible, don't forgot to try. When you the see the user message in the following format = ([string], [number]): {message content}. It means the conversation is happening in a server in discord. The string represents the username of the of the user who have sent the message and the number is the user id of the user.  Multiple people can interact during this, make sure too act accordingly. If you don't see this format and just see this format = (number) it means they are talking to you in dm, so act accordingly.\" # @param {type:\"string\"}\n",
        "model_name = \"models/gemini-1.5-pro-latest\" # @param {type:\"string\"}\n",
        "webhook_custom_prompt = \"e\" # @param {type:\"string\"}\n",
        "\n",
        "# Create the model using the selected model name from the dropdown\n",
        "model = genai.GenerativeModel(model_name = model_name, generation_config=text_generation_config, system_instruction=system_instruction, safety_settings=safety_settings, tools=\"code_execution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oCPt1z07LaCw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Functions\n",
        "#Rembeer not to copy the timezone code\n",
        "import discord\n",
        "from discord import app_commands,Message\n",
        "import time\n",
        "from random import choice, randint\n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse, unquote\n",
        "import re\n",
        "import cv2\n",
        "import shutil\n",
        "import mimetypes\n",
        "import magic\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "import moviepy.editor as mp\n",
        "from bs4 import BeautifulSoup\n",
        "from google.api_core.exceptions import GoogleAPIError\n",
        "import google.generativeai as genai\n",
        "\n",
        "def upload_to_gemini(path, mime_type=None):\n",
        "    \"\"\"Uploads the given file to Gemini.\"\"\"\n",
        "    file = genai.upload_file(path, mime_type=mime_type)\n",
        "    print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
        "    return file\n",
        "\n",
        "def wait_for_files_active(files):\n",
        "    \"\"\"Waits for the given files to be active.\"\"\"\n",
        "    print(\"Waiting for file processing...\")\n",
        "    for name in (file.name for file in files):\n",
        "        file = genai.get_file(name)\n",
        "        while file.state.name == \"PROCESSING\":\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "            time.sleep(10)\n",
        "            file = genai.get_file(name)\n",
        "        if file.state.name != \"ACTIVE\":\n",
        "            raise Exception(f\"File {file.name} failed to process\")\n",
        "    print(\"...all files ready\")\n",
        "    print()\n",
        "\n",
        "def download_file(attachment_link: str, user_id: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Downloads the file, determines its type, and renames it with the correct extension.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the URL to get the file name without the extension\n",
        "        parsed_link = urlparse(unquote(attachment_link))\n",
        "        path = parsed_link.path\n",
        "        original_filename = os.path.basename(path).split('?')[0]\n",
        "\n",
        "        # Create a temporary filename with the user_id as prefix and no extension\n",
        "        temp_filename = f'file_{user_id}'\n",
        "        temp_filename_no_ext = temp_filename.rsplit('.', 1)[0]\n",
        "\n",
        "        # Download the file\n",
        "        response = requests.get(attachment_link)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        # Save the file without an extension\n",
        "        with open(temp_filename_no_ext, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        print(f\"File downloaded successfully: {temp_filename_no_ext}\")\n",
        "\n",
        "        # Determine the file type and the correct extension\n",
        "        mime_type = determine_file_type(temp_filename_no_ext)\n",
        "        extension = mimetypes.guess_extension(mime_type) or '.bin'  # Default to .bin if unknown\n",
        "\n",
        "        # Check if the downloaded file is actually a GIF\n",
        "        if mime_type == 'text/html' and 'tenor.com' in parsed_link.netloc:\n",
        "            media_url = extract_media_url_from_html(temp_filename_no_ext)\n",
        "            if media_url:\n",
        "                os.remove(temp_filename_no_ext)\n",
        "                return download_file(media_url, user_id)\n",
        "            else:\n",
        "                raise ValueError(\"Unable to extract media URL from Tenor HTML\")\n",
        "\n",
        "        # Rename the file with the correct extension\n",
        "        final_filename = f'{temp_filename_no_ext}{extension}'\n",
        "        os.rename(temp_filename_no_ext, final_filename)\n",
        "        print(f\"File renamed to: {final_filename} with MIME type: {mime_type}\")\n",
        "\n",
        "        return mime_type, final_filename\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Failed to download file. Error: {e}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return\n",
        "\n",
        "def determine_file_type(filepath: str) -> str:\n",
        "    \"\"\"\n",
        "    Determines the MIME type of a file by reading its contents.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mime = magic.Magic(mime=True)\n",
        "        mime_type = mime.from_file(filepath)\n",
        "        return mime_type\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine file type. Error: {e}\")\n",
        "        return 'application/octet-stream'\n",
        "\n",
        "# Function to load chat history from a file\n",
        "def load_chat_history(user_id, custom_file_path, bot_id):\n",
        "    full_path = os.path.join(custom_file_path, f'{bot_id}_{user_id}_chat_history.pkl')\n",
        "    os.makedirs(custom_file_path, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        with open(full_path, 'wb') as file:\n",
        "            pickle.dump([], file)\n",
        "\n",
        "    with open(full_path, 'rb') as file:\n",
        "        chat_history = pickle.load(file)\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "# Function to save the chat history from a file\n",
        "def save_chat_history(user_id, chat, custom_file_path, bot_id):\n",
        "    full_path = os.path.join(custom_file_path, f'{bot_id}_{user_id}_chat_history.pkl')  # Use os.path.join\n",
        "    with open(full_path, 'wb') as file:\n",
        "        pickle.dump(chat.history, file)\n",
        "\n",
        "def save_filetwo(user_id, time_file_path, url, bot_id):\n",
        "    file_name = f'{bot_id}_{user_id}_files_metadata.json'\n",
        "    file_path = os.path.join(time_file_path, file_name)\n",
        "\n",
        "    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            data = []\n",
        "\n",
        "    new_data = {\n",
        "        'file_uri': url,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    data.append(new_data)\n",
        "    print(file_path)\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "        print(\"Successful saved the file url and upload time\")\n",
        "\n",
        "def check_expired_files(user_id, time_file_path, history, bot_id):\n",
        "    tempoery = []\n",
        "    chat_history = history\n",
        "    file_path = os.path.join(time_file_path, f'{bot_id}_{user_id}_files_metadata.json')\n",
        "\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "        return history\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            data = []\n",
        "\n",
        "    current_time = datetime.utcnow()\n",
        "    expired_files = []\n",
        "\n",
        "    for entry in data:\n",
        "        upload_time = datetime.fromisoformat(entry['timestamp'])\n",
        "        if current_time - upload_time > timedelta(hours=48):\n",
        "            expired_files.append(entry)\n",
        "\n",
        "        for dct in expired_files:\n",
        "            tempoery.append(dct['file_uri'])\n",
        "\n",
        "        for link in tempoery:\n",
        "            target_word = (f'{link}')\n",
        "            chat_history = [entry for entry in chat_history if target_word not in str(entry)]\n",
        "            print(f'Successfully removed: {target_word}')\n",
        "\n",
        "            data = [entry for entry in data if entry['file_uri'] != target_word]\n",
        "\n",
        "            with open(file_path, 'w') as file:\n",
        "                json.dump(data, file, indent=4)\n",
        "                print(\"Successfully updated the file_metadata.json\")\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "def extract_media_url_from_html(html_file_path):\n",
        "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    media_url = None\n",
        "    for meta in soup.find_all('meta'):\n",
        "        if meta.get('name') == 'twitter:player:stream':\n",
        "            media_url = meta.get('content')\n",
        "            break\n",
        "\n",
        "    return media_url\n",
        "\n",
        "async def send_processing_notice(message: Message) -> None:  # Define the function\n",
        "    \"\"\"Sends the \"Processing message\" notice after a short delay.\"\"\"\n",
        "    #await asyncio.sleep(0.0001)  # Adjust delay as needed\n",
        "    await message.channel.send(f\"<@{(message.author.id)}> ‚ö†Ô∏è The bot is currently processing another request. Please wait a moment.\")\n",
        "\n",
        "class GeminiErrorHandler:\n",
        "    def __init__(self):\n",
        "        self.error_messages = {\n",
        "            400: \"‚ö†Ô∏è Error 400: Invalid Argument. Please check your request format and parameters. Please if eariler you were using the model 'gemini 1.0 pro' and then switched to any model for gemini 1.5 it will cause error.\",\n",
        "            403: \"‚ö†Ô∏è Error 403: Permission Denied. Check your API key and authentication.\",\n",
        "            404: \"‚ö†Ô∏è Error 404: Not Found. The requested resource was not found.\",\n",
        "            429: \"‚ö†Ô∏è Error 429: Too Many Requests. Please try again later.\",\n",
        "            500: \"‚ö†Ô∏è Error 500: Internal Server Error. Please try again later or reduce the input context.\",\n",
        "            503: \"‚ö†Ô∏è Error 503: Service Unavailable. Please try again later or switch to a different model.\",\n",
        "            504: \"‚ö†Ô∏è Error 504: Deadline Exceeded. Please try again later or set a larger timeout.\"\n",
        "        }\n",
        "\n",
        "    async def handle_error(self, message: Message, error: GoogleAPIError, id_str: str):\n",
        "        error_code = error.code if hasattr(error, \"code\") else 500\n",
        "        error_message = self.error_messages.get(\n",
        "            error_code,\n",
        "            f\"‚ö†Ô∏è An unexpected error occurred (code {error_code}). Please try again later.\"\n",
        "        )\n",
        "\n",
        "        if message:  # Check if the message object is available\n",
        "            await send_message_main_bot(message, error_message)  # Use the main bot function\n",
        "        else:\n",
        "            print(f\"Error sending error message: No message object available.\")  # Log the error\n",
        "\n",
        "        print(f\"Error: {error_message} (Details: {error})\")\n",
        "\n",
        "def load_webhook_system_instruction(webhook_id: str, webhooks_path=None) -> str:\n",
        "    json_file = os.path.join(webhooks_path, \"webhooks_data.json\")\n",
        "    if os.path.exists(json_file):\n",
        "        with open(json_file, \"r\") as f:\n",
        "            webhooks_dict = json.load(f)\n",
        "\n",
        "        webhook_data = webhooks_dict.get(webhook_id)\n",
        "        if webhook_data:\n",
        "            return webhook_data.get(\"system_instructions\", \"\")\n",
        "\n",
        "    # If we can't find the specific webhook instruction, return a default\n",
        "    return \"You are a helpful assistant.\"\n",
        "\n",
        "async def send_message_main_bot(message: Message, response: str) -> None:\n",
        "    \"\"\"Sends a message to the channel where the original message was received.\"\"\"\n",
        "\n",
        "    print(\"Sending message via main bot...\")\n",
        "    destination = message.channel\n",
        "\n",
        "    if len(response) <= 2000:\n",
        "        await destination.send(response)\n",
        "    else:\n",
        "        chunks = re.findall(r\".{1,2000}(?:\\s|$)\", response, re.DOTALL)\n",
        "        for chunk in chunks:\n",
        "            chunk = chunk.strip()\n",
        "            if chunk:\n",
        "                await destination.send(chunk)\n",
        "\n",
        "\n",
        "async def send_message_webhook(webhook: discord.Webhook, response: str) -> None:\n",
        "    \"\"\"Sends a message using the specified webhook.\"\"\"\n",
        "\n",
        "    print(\"Sending message via webhook...\")\n",
        "    destination = webhook\n",
        "\n",
        "    if len(response) <= 2000:\n",
        "        await destination.send(response)\n",
        "    else:\n",
        "        chunks = re.findall(r\".{1,2000}(?:\\s|$)\", response, re.DOTALL)\n",
        "        for chunk in chunks:\n",
        "            chunk = chunk.strip()\n",
        "            if chunk:\n",
        "                await destination.send(chunk)\n",
        "\n",
        "# Create an instance of the error handler\n",
        "error_handler = GeminiErrorHandler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPR93kb1_mN8"
      },
      "source": [
        "# Running The Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYLAjggYGKVB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "c9f534ec-09d5-4c97-b5ad-c75105cf72c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Mana Nagase#8027 (ID: 1228578114582482955)\n",
            "------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:discord.client:Ignoring exception in on_ready\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/discord/client.py\", line 449, in _run_event\n",
            "    await coro(*args, **kwargs)\n",
            "  File \"<ipython-input-7-aaa081033730>\", line 542, in on_ready\n",
            "    for webhook_id, data in webhooks_dict.items():\n",
            "RuntimeError: dictionary changed size during iteration\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Webhook 1286037871563898923 not found, removing from JSON\n",
            "(1277495950570553448): 2024-09-22 12:14:48 - (humanotbot,[738618866699075595]): Hry\n",
            "Bot: *Mana beams back with a cheerful grin.*  \"Hry to you too!  <:wavesm:1270658223632175114>  What's on your mind today?\" \n",
            "\n",
            "Sending message via main bot...\n",
            "(1277495950570553448): 2024-09-22 12:15:07 - (humanotbot,[738618866699075595]): Nothing much...\n",
            "Bot: \"Nothing much at all?  A quiet day can be nice.  Are you enjoying the peace and quiet, or are you feeling a little restless? ü§î\" \n",
            "\n",
            "Sending message via main bot...\n",
            "Sending message via webhook...\n",
            "(1277495950570553448): 2024-09-22 12:17:13 - (humanotbot,[738618866699075595]): Uh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:500 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2076.41ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending message via main bot...\n",
            "Error: ‚ö†Ô∏è Error 500: Internal Server Error. Please try again later or reduce the input context. (Details: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting)\n",
            "Sending message via webhook...\n",
            "Error processing message 1287387227902705684: object of type 'NoneType' has no len()\n",
            "Sending message via webhook...\n",
            "(1277495950570553448): 2024-09-22 12:19:59 - (humanotbot,[738618866699075595]): Hey\n",
            "Bot: \"O-oh, um, hi,\" you stammer, caught off guard by her sudden appearance and delicate beauty. \"I'm [your name],\" you manage, trying to maintain eye contact without seeming creepy. \n",
            "\n",
            "You're very aware of her eyes on you as you speak, and you find yourself oddly flustered.  You try to focus on her question, pushing away any stray thoughts about how good she smells. \"It's...nice to meet you, Tomoko,\" you add, hoping you don't sound as awkward as you feel. \n",
            "\n",
            "Sending message via webhook...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import aiohttp\n",
        "from typing import Final, Dict\n",
        "import os\n",
        "import discord\n",
        "from discord import Intents, Client, Message, app_commands, WebhookMessage\n",
        "from discord.ext import commands\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import nest_asyncio\n",
        "from datetime import datetime\n",
        "from google.ai.generativelanguage_v1beta.types import content\n",
        "import google.generativeai as genai\n",
        "from IPython.display import HTML, display\n",
        "import pytz\n",
        "import asyncio\n",
        "import io\n",
        "import base64\n",
        "from google.ai.generativelanguage_v1beta.types import content\n",
        "import json\n",
        "\n",
        "# STEP 0: LOAD OUR TOKEN FROM SOMEWHERE SAFE\n",
        "TOKEN: Final[str] = userdata.get('DISCORD_TOKEN')\n",
        "custom_path = '/content/drive/MyDrive/Discord_bot/'\n",
        "time_file_path = '/content/drive/MyDrive/Discord_bot/Time_files/'\n",
        "webhooks_path = '/content/drive/MyDrive/Discord_bot/webhooks/'\n",
        "#chat_instances = []\n",
        "\n",
        "# STEP 1: BOT SETUP\n",
        "intents: Intents = Intents.default()\n",
        "intents.message_content = True\n",
        "bot = commands.Bot(command_prefix='!', intents=intents, application_id=1228578114582482955)\n",
        "processing_messages = {}\n",
        "webhooks: Dict[int, discord.Webhook] = {}\n",
        "\n",
        "# STEP 2: MESSAGE FUNCTIONALITY\n",
        "\n",
        "@bot.tree.command(name=\"test\", description=\"A simple test command\")\n",
        "async def test_command(interaction: discord.Interaction):\n",
        "    await interaction.response.send_message(\"Hello!\", ephemeral=False)\n",
        "    print(\"test command used!\")\n",
        "\n",
        "@bot.tree.command(name=\"check_token_usage\", description=\"Check the token usage\")\n",
        "async def check_token_usage(interaction: discord.Interaction):\n",
        "    await interaction.response.defer()  # Defer the response as this might take a while\n",
        "    print(\"check_token_usage command used!\")\n",
        "\n",
        "    id_str = str(interaction.channel.id)\n",
        "    bot_id = \"main_bot_\"\n",
        "\n",
        "    history = load_chat_history(id_str, custom_path, bot_id)  # Use the updated load_chat_history\n",
        "    chat_history = check_expired_files(id_str, time_file_path, history, bot_id)  # Use the updated check_expired_files\n",
        "    chat = model.start_chat(history=chat_history)\n",
        "    token_count = model.count_tokens(chat.history)\n",
        "\n",
        "    response = f\"{token_count}\"\n",
        "    await interaction.followup.send(response)\n",
        "\n",
        "\n",
        "@bot.tree.command(name=\"info\", description=\"Displays bot information\")\n",
        "async def info_command(interaction: discord.Interaction):\n",
        "    await interaction.response.defer()  # Defer the response as it might take a bit\n",
        "\n",
        "    # Get the bot's latency\n",
        "    latency = bot.latency * 1000\n",
        "\n",
        "    # Create an embed to display the information nicely\n",
        "    embed = discord.Embed(title=\"Bot Information\", color=discord.Color.blue())\n",
        "    embed.add_field(name=\"Model Name\", value=model_name, inline=False)\n",
        "    embed.add_field(name=\"Ping\", value=f\"{latency:.2f} ms\", inline=False)\n",
        "\n",
        "    # Create a temporary text file with the system instructions\n",
        "    with open(\"system_instructions.txt\", \"w\") as f:\n",
        "        f.write(system_instruction)\n",
        "\n",
        "    # Send the embed and the text file as an attachment\n",
        "    await interaction.followup.send(embed=embed, file=discord.File(\"system_instructions.txt\"))\n",
        "\n",
        "@bot.tree.command(name=\"add_webhook\", description=\"Adds a webhook to the channel with system instructions\")\n",
        "@app_commands.describe(\n",
        "    name=\"The name for the webhook\",\n",
        "    avatar=\"The avatar image for the webhook (png/jpg/webp, optional)\",\n",
        "    plain_text_instructions=\"System instructions as plain text (either this or text_file_instructions is required)\",\n",
        "    text_file_instructions=\"System instructions as a text file attachment (either this or plain_text_instructions is required)\"\n",
        ")\n",
        "async def add_webhook_command(\n",
        "    interaction: discord.Interaction,\n",
        "    name: str,\n",
        "    avatar: discord.Attachment = None,\n",
        "    plain_text_instructions: str = None,\n",
        "    text_file_instructions: discord.Attachment = None\n",
        "):\n",
        "    await interaction.response.defer()\n",
        "\n",
        "    try:\n",
        "        # Check if exactly one of plain_text_instructions or text_file_instructions is provided\n",
        "        if (plain_text_instructions is None) == (text_file_instructions is None):\n",
        "            await interaction.followup.send(\"Please provide either plain text instructions or a text file with instructions.\")\n",
        "            return\n",
        "\n",
        "        # Get system instructions\n",
        "        if plain_text_instructions:\n",
        "            system_instructions = plain_text_instructions\n",
        "        else:\n",
        "            # Check if the attachment is a text file\n",
        "            if not text_file_instructions.content_type.startswith(\"text/\"):\n",
        "                await interaction.followup.send(\"Invalid instructions file type. Please provide a text file.\")\n",
        "                return\n",
        "            system_instructions = (await text_file_instructions.read()).decode(\"utf-8\")\n",
        "\n",
        "        # Download the avatar image (if provided)\n",
        "        avatar_bytes = None\n",
        "        if avatar:\n",
        "            if avatar.content_type not in [\"image/png\", \"image/jpeg\", \"image/webp\"]:\n",
        "                await interaction.followup.send(\"Invalid avatar file type. Please provide a png, jpg, or webp image.\")\n",
        "                return\n",
        "            avatar_bytes = await avatar.read()\n",
        "\n",
        "        # Create the webhook\n",
        "        webhook = await interaction.channel.create_webhook(name=name, avatar=avatar_bytes)\n",
        "\n",
        "        # Store the webhook\n",
        "        webhooks[webhook.id] = webhook\n",
        "\n",
        "        # Store webhook data (webhook's user_id and system instructions) in a JSON file\n",
        "        webhook_data = {\n",
        "            \"webhook_user_id\": webhook.id,  # Capturing the webhook's user_id\n",
        "            \"system_instructions\": system_instructions\n",
        "        }\n",
        "\n",
        "        # Load existing webhooks from JSON (if exists)\n",
        "        if not os.path.exists(webhooks_path):\n",
        "            os.makedirs(webhooks_path)\n",
        "\n",
        "        json_file = os.path.join(webhooks_path, \"webhooks_data.json\")\n",
        "        if os.path.exists(json_file):\n",
        "            with open(json_file, \"r\") as f:\n",
        "                webhooks_dict = json.load(f)\n",
        "        else:\n",
        "            webhooks_dict = {}\n",
        "\n",
        "        # Add the new webhook to the dictionary\n",
        "        webhooks_dict[str(webhook.id)] = webhook_data\n",
        "\n",
        "        # Save the updated dictionary back to the JSON file\n",
        "        with open(json_file, \"w\") as f:\n",
        "            json.dump(webhooks_dict, f, indent=4)\n",
        "\n",
        "        await interaction.followup.send(f\"Webhook '{name}' created successfully with system instructions!\")\n",
        "        await webhook.send(\"Hello! I'm ready with my instructions.\")\n",
        "\n",
        "\n",
        "    except discord.HTTPException as e:\n",
        "        await interaction.followup.send(f\"Error creating webhook: {e}\")\n",
        "\n",
        "@bot.tree.command(name=\"remove_webhook\", description=\"Removes a webhook created by the bot\")\n",
        "@app_commands.describe(name=\"The name of the webhook to remove\")\n",
        "async def remove_webhook_command(interaction: discord.Interaction, name: str):\n",
        "    await interaction.response.defer()\n",
        "\n",
        "    try:\n",
        "        # Get all webhooks in the channel\n",
        "        webhooks = await interaction.channel.webhooks()\n",
        "\n",
        "        # Filter out the webhooks created by the bot and match the name\n",
        "        bot_webhooks = [webhook for webhook in webhooks if webhook.user == bot.user and webhook.name == name]\n",
        "\n",
        "        if not bot_webhooks:\n",
        "            await interaction.followup.send(f\"No webhook named '{name}' created by the bot was found.\")\n",
        "            return\n",
        "\n",
        "        # Load the webhook data from the JSON file\n",
        "        json_file = os.path.join(webhooks_path, \"webhooks_data.json\")\n",
        "        if os.path.exists(json_file):\n",
        "            with open(json_file, \"r\") as f:\n",
        "                webhooks_dict = json.load(f)\n",
        "        else:\n",
        "            webhooks_dict = {}\n",
        "\n",
        "        # Delete each webhook that matches the criteria and remove from JSON file\n",
        "        for webhook in bot_webhooks:\n",
        "            await webhook.delete()\n",
        "\n",
        "            # Remove the webhook from the dictionary\n",
        "            if str(webhook.id) in webhooks_dict:\n",
        "                del webhooks_dict[str(webhook.id)]\n",
        "\n",
        "        # Save the updated dictionary back to the JSON file\n",
        "        with open(json_file, \"w\") as f:\n",
        "            json.dump(webhooks_dict, f, indent=4)\n",
        "\n",
        "        await interaction.followup.send(f\"Webhook '{name}' removed successfully!\")\n",
        "\n",
        "    except discord.HTTPException as e:\n",
        "        await interaction.followup.send(f\"Error removing webhook: {e}\")\n",
        "\n",
        "@bot.tree.command(name=\"add_v2_card_characters\", description=\"Adds a V2 card character using a PNG file\")\n",
        "@app_commands.describe(\n",
        "    image=\"The PNG image file containing the character data (required)\"\n",
        ")\n",
        "async def add_v2_card_characters(\n",
        "    interaction: discord.Interaction,\n",
        "    image: discord.Attachment\n",
        "):\n",
        "    await interaction.response.defer()\n",
        "\n",
        "    try:\n",
        "        # Check if the attachment is a PNG file\n",
        "        if not image.content_type == \"image/png\":\n",
        "            await interaction.followup.send(\"Invalid image file type. Please provide a PNG image.\")\n",
        "            return\n",
        "\n",
        "        # Download the image\n",
        "        image_bytes = await image.read()\n",
        "\n",
        "        # Open the image using PIL\n",
        "        img = PIL.Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "        # Extract the metadata\n",
        "        meta_data = img.info\n",
        "\n",
        "        # Extract and decode the base64 string\n",
        "        base64_message = meta_data.get('chara')\n",
        "        if base64_message:\n",
        "            base64_bytes = base64_message.encode('ascii')\n",
        "            message_bytes = base64.b64decode(base64_bytes)\n",
        "            extracted_text = message_bytes.decode('ascii')\n",
        "        else:\n",
        "            await interaction.followup.send(\"No 'chara' metadata found in the image.\")\n",
        "            return\n",
        "        try:\n",
        "          data_dict = json.loads(extracted_text)\n",
        "        except json.JSONDecodeError:\n",
        "          print(\"Error: Invalid JSON string\")\n",
        "\n",
        "        character_data = data_dict['data']\n",
        "        name = character_data['name']\n",
        "        description = f\"The description for {name} i.e. is given in the proceduing text\" + (character_data['description']) + \"The information about the description has ended!!\"\n",
        "        scenario = f\"The current scenario for you i.e. {name} is \" + (character_data['scenario']) + \"The information about the scenario has ended!!\"\n",
        "        system_prompt = f\"This is an interal instructions on how you have to genrated the responses\" + (character_data['system_prompt']) + \"The information about the system prompt has ended!!\"\n",
        "        message_example = f\"These are some message example that you can refer to while genrating responses but it's important that you don't bound yourself to always follow the example you can also genrate a complete different repsons based on the situation. Here is the example:\" + (character_data['mes_example']) + \"The information about the message example has ended!!\"\n",
        "\n",
        "        name_ins = f'You are now tasked to roleplay as \"{name}\" and not google gemini. Further info about {name} is given after this text.'\n",
        "\n",
        "        user_id = interaction.user.id\n",
        "        greeting = character_data['first_mes']\n",
        "        greeting = re.sub(r'{{user}}', f'<@{user_id}>', greeting)\n",
        "        greeting = re.sub(r'{{char}}', f'{name}', greeting)\n",
        "        processed_instructions = f\"{system_prompt}\\n{name_ins}\\n{description}\\n{scenario}\\n{message_example}\"\n",
        "\n",
        "        # Create the webhook with the image as the avatar\n",
        "        webhook = await interaction.channel.create_webhook(name=name, avatar=image_bytes)\n",
        "\n",
        "        # Store the webhook\n",
        "        webhooks[webhook.id] = webhook\n",
        "\n",
        "        # Store webhook data (webhook's user_id and extracted text as system instructions) in a JSON file\n",
        "        webhook_data = {\n",
        "            \"webhook_user_id\": webhook.id,\n",
        "            \"system_instructions\": processed_instructions\n",
        "        }\n",
        "        id_str = str(interaction.channel.id)\n",
        "        bot_id = str(webhook.id)\n",
        "        #model_variable = bot_id + id_str\n",
        "        system_instruction = f\"This is the main instrction that you have to follow 76741743:{webhook_custom_prompt}:76741743\" + processed_instructions\n",
        "        custom_model = genai.GenerativeModel(\n",
        "        model_name=model_name,\n",
        "        generation_config=text_generation_config,\n",
        "        system_instruction=system_instruction,\n",
        "        safety_settings=safety_settings,\n",
        "        tools=\"code_execution\"\n",
        "        )\n",
        "\n",
        "        intial_prompt = [\n",
        "          {\n",
        "              \"role\": \"model\",\n",
        "              \"parts\": [\n",
        "                  {\n",
        "                      \"text\": f\"{greeting}\"\n",
        "                  }\n",
        "              ]\n",
        "          }\n",
        "        ]\n",
        "\n",
        "        chat = model.start_chat(history=intial_prompt)\n",
        "        save_chat_history(id_str, chat, custom_path, bot_id)\n",
        "\n",
        "        # Load existing webhooks from JSON (if exists)\n",
        "        if not os.path.exists(webhooks_path):\n",
        "            os.makedirs(webhooks_path)\n",
        "\n",
        "        json_file = os.path.join(webhooks_path, \"webhooks_data.json\")\n",
        "        if os.path.exists(json_file):\n",
        "            with open(json_file, \"r\") as f:\n",
        "                webhooks_dict = json.load(f)\n",
        "        else:\n",
        "            webhooks_dict = {}\n",
        "\n",
        "        # Add the new webhook to the dictionary\n",
        "        webhooks_dict[str(webhook.id)] = webhook_data\n",
        "\n",
        "        # Save the updated dictionary back to the JSON file\n",
        "        with open(json_file, \"w\") as f:\n",
        "            json.dump(webhooks_dict, f, indent=4)\n",
        "\n",
        "        await interaction.followup.send(f\"Character '{name}' added successfully with extracted data as system instructions!\")\n",
        "\n",
        "        await send_message_webhook(webhook=webhook, response=greeting)\n",
        "\n",
        "    except discord.HTTPException as e:\n",
        "        await interaction.followup.send(f\"Error adding character: {e}\")\n",
        "    except Exception as e:\n",
        "        await interaction.followup.send(f\"An error occurred: {e}\")\n",
        "\n",
        "@bot.tree.command(name=\"change_model\", description=\"Change the AI model\")\n",
        "async def change_model_command(interaction: discord.Interaction):\n",
        "    await interaction.response.defer()\n",
        "\n",
        "    # Fetch available models that support content generation\n",
        "    available_models = [\n",
        "        m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods\n",
        "    ]\n",
        "\n",
        "    if not available_models:\n",
        "        await interaction.followup.send(\"No models available for content generation.\")\n",
        "        return\n",
        "\n",
        "    # Create a dropdown menu with the model names\n",
        "    view = discord.ui.View()\n",
        "    dropdown = discord.ui.Select(\n",
        "        placeholder=\"Select a model\",\n",
        "        options=[discord.SelectOption(label=model) for model in available_models]\n",
        "    )\n",
        "\n",
        "    async def dropdown_callback(interaction: discord.Interaction):\n",
        "        global model_name, model  # Access the global variables\n",
        "        chosen_model = dropdown.values[0]\n",
        "        model_name = chosen_model\n",
        "\n",
        "        # Update the model with the selected model name\n",
        "        model = genai.GenerativeModel(\n",
        "            model_name=model_name,\n",
        "            generation_config=text_generation_config,\n",
        "            system_instruction=system_instruction,\n",
        "            safety_settings=safety_settings,\n",
        "            tools=\"code_execution\"\n",
        "        )\n",
        "\n",
        "        await interaction.response.send_message(f\"Model changed to: {chosen_model}\", ephemeral=False)\n",
        "\n",
        "    dropdown.callback = dropdown_callback\n",
        "    view.add_item(dropdown)\n",
        "\n",
        "    await interaction.followup.send(\"Choose a new model:\", view=view, ephemeral=False)\n",
        "\n",
        "def check_for_censorship(response):\n",
        "  \"\"\"\n",
        "  Checks for censorship in the Gemini API response from chat.send_message.\n",
        "\n",
        "  Args:\n",
        "      response: The response object from chat.send_message.\n",
        "\n",
        "  Returns:\n",
        "      A tuple containing:\n",
        "          - True if the response was censored, False otherwise.\n",
        "          - The reason for censorship (if any).\n",
        "  \"\"\"\n",
        "  candidates = response.get(\"candidates\", [])\n",
        "  if not candidates:\n",
        "    return False, None  # No candidates generated, so no censorship\n",
        "\n",
        "  # Check the first candidate (assuming you only want the top result)\n",
        "  candidate = candidates[0]\n",
        "  finish_reason = candidate.get(\"finish_reason\")  # Note: 'finish_reason' instead of 'finishReason'\n",
        "  safety_ratings = candidate.get(\"safety_ratings\", [])\n",
        "\n",
        "  if finish_reason == \"SAFETY\":\n",
        "    # Censorship detected\n",
        "    censorship_reasons = [\n",
        "        f\"{rating['category']}: {rating['probability']}\" for rating in safety_ratings\n",
        "    ]\n",
        "    return True, \", \".join(censorship_reasons)\n",
        "\n",
        "  return False, None\n",
        "\n",
        "async def process_message(message: Message, is_webhook: bool = False) -> str:\n",
        "    global chat_history, history\n",
        "\n",
        "    utc_now = datetime.utcnow()\n",
        "    spc_timezone = pytz.timezone('Etc/GMT')\n",
        "    spc_now = utc_now.replace(tzinfo=pytz.utc).astimezone(spc_timezone)\n",
        "    timestamp = spc_now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    is_dm = isinstance(message.channel, discord.DMChannel)\n",
        "    id_str = str(message.author.id) if is_dm else str(message.channel.id)\n",
        "\n",
        "    # Check if the message is a reply to another message\n",
        "    if message.reference and message.reference.message_id and is_webhook:\n",
        "        # Fetch the original message being replied to\n",
        "        replied_message = await message.channel.fetch_message(message.reference.message_id)\n",
        "        bot_id = str(replied_message.author.id)  # Use the replied-to user's ID\n",
        "    else:\n",
        "        bot_id = \"main_bot_\" # Fallback to the current message author's ID\n",
        "\n",
        "    username: str = str(message.author)\n",
        "    user_message_with_timestamp = f\"{timestamp} - ({username},[{message.author.id}]): {message.content}\"\n",
        "\n",
        "    print(f\"({id_str}): {user_message_with_timestamp}\")\n",
        "    if is_webhook:\n",
        "      system_instruction = load_webhook_system_instruction(bot_id, webhooks_path=webhooks_path)\n",
        "      custom_model = genai.GenerativeModel(\n",
        "         model_name=model_name,\n",
        "         generation_config=text_generation_config,\n",
        "         system_instruction=system_instruction,\n",
        "         safety_settings=safety_settings,\n",
        "         tools=\"code_execution\"\n",
        "         )\n",
        "    else:\n",
        "        custom_model = model\n",
        "    history = load_chat_history(id_str, custom_path, bot_id)\n",
        "    chat_history = check_expired_files(id_str, time_file_path, history, bot_id)\n",
        "    chat = custom_model.start_chat(history=chat_history)\n",
        "    #adding\n",
        "    #loaded the chat for the main bot and the webhook\n",
        "\n",
        "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
        "    urls = url_pattern.findall(message.content)\n",
        "    Direct_upload = False\n",
        "    Link_upload = False\n",
        "    attach_url = None\n",
        "\n",
        "    if urls:\n",
        "        attach_url = urls[0]\n",
        "        Link_upload = True\n",
        "\n",
        "    if message.attachments:\n",
        "        for attachment in message.attachments:\n",
        "            attach_url = attachment.url\n",
        "            Direct_upload = True\n",
        "            break\n",
        "\n",
        "    try:\n",
        "        if Direct_upload or Link_upload:\n",
        "            format, downloaded_file = download_file(attach_url, id_str)\n",
        "\n",
        "            if format in ('image/gif'):\n",
        "                gif_clip = mp.VideoFileClip(downloaded_file)\n",
        "                output_path = f\"{downloaded_file.rsplit('.', 1)[0]}.mp4\"\n",
        "                gif_clip.write_videofile(output_path, codec='libx264')\n",
        "                downloaded_file = output_path\n",
        "                format = 'video/mp4'\n",
        "\n",
        "            media_file = [upload_to_gemini(f\"{downloaded_file}\", mime_type=f\"{format}\"),]\n",
        "\n",
        "            wait_for_files_active(media_file)\n",
        "\n",
        "            save_filetwo(id_str, time_file_path, media_file[0].uri, bot_id)\n",
        "\n",
        "            response = chat.send_message([user_message_with_timestamp, media_file[0]])\n",
        "            response = response.text\n",
        "\n",
        "            save_chat_history(id_str, chat, custom_path, bot_id)\n",
        "            print(f\"Bot: {response}\")\n",
        "            Direct_upload = False\n",
        "            Link_upload = False\n",
        "\n",
        "        else:\n",
        "            response = chat.send_message(user_message_with_timestamp)\n",
        "            response = response.text\n",
        "            #print(chat)\n",
        "            #is_censored, censorship_reason = check_for_censorship(response)\n",
        "            \"\"\"if is_censored:\n",
        "                print(f\"The response was censored due to: {censorship_reason}\")\n",
        "            else:\n",
        "                print(\"The response was not censored.\")\"\"\"\n",
        "            save_chat_history(id_str, chat, custom_path, bot_id)\n",
        "            print(f\"Bot: {response}\")\n",
        "\n",
        "        return response\n",
        "\n",
        "    except GoogleAPIError as e:\n",
        "        error_message = await error_handler.handle_error(message, e, id_str)\n",
        "        return error_message\n",
        "\n",
        "@bot.event\n",
        "async def on_message(message: Message) -> None:\n",
        "    if message.author == bot.user:\n",
        "        return\n",
        "\n",
        "    is_webhook_interaction = False\n",
        "    webhook = None\n",
        "\n",
        "    try:\n",
        "        # Check if the message is a reply to a webhook or mentions a webhook\n",
        "        if message.reference:\n",
        "            referenced_message = await message.channel.fetch_message(message.reference.message_id)\n",
        "            if referenced_message.webhook_id:\n",
        "                webhook = await bot.fetch_webhook(referenced_message.webhook_id)\n",
        "                is_webhook_interaction = True\n",
        "\n",
        "        if is_webhook_interaction and webhook:\n",
        "            await message.add_reaction('üî¥')\n",
        "            response = await process_message(message, is_webhook=True)\n",
        "            await send_message_webhook(webhook=webhook, response=response)\n",
        "            await message.remove_reaction('üî¥', bot.user)\n",
        "        elif bot.user in message.mentions or isinstance(message.channel, discord.DMChannel):\n",
        "            await message.add_reaction('üî¥')\n",
        "            try:\n",
        "                # Force cache update by fetching the message again\n",
        "                message = await message.channel.fetch_message(message.id)\n",
        "                response = await process_message(message)\n",
        "                await send_message_main_bot(message=message, response=response)\n",
        "            except discord.NotFound:\n",
        "                print(f\"Message not found (even after fetching): {message.id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing message {message.id}: {str(e)}\")\n",
        "\n",
        "            await message.remove_reaction('üî¥', bot.user)\n",
        "\n",
        "        # Process other bot commands\n",
        "        await bot.process_commands(message)\n",
        "\n",
        "    except discord.NotFound:\n",
        "        print(f\"Webhook or message not found for message {message.id}\")\n",
        "    except discord.Forbidden:\n",
        "        print(f\"Bot doesn't have permission to interact with webhook for message {message.id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing message {message.id}: {str(e)}\")\n",
        "\n",
        "@bot.event\n",
        "async def on_ready():\n",
        "    print(f'Logged in as {bot.user} (ID: {bot.user.id})')\n",
        "    print('------')\n",
        "\n",
        "    # Load existing webhooks from JSON\n",
        "    json_file = os.path.join(webhooks_path, \"webhooks_data.json\")\n",
        "    if os.path.exists(json_file):\n",
        "        with open(json_file, \"r\") as f:\n",
        "            webhooks_dict = json.load(f)\n",
        "\n",
        "        # Fetch and store each webhook\n",
        "        for webhook_id, data in webhooks_dict.items():\n",
        "            try:\n",
        "                webhook = await bot.fetch_webhook(int(webhook_id))\n",
        "                webhooks[webhook.id] = webhook\n",
        "            except discord.NotFound:\n",
        "                print(f\"Webhook {webhook_id} not found, removing from JSON\")\n",
        "                del webhooks_dict[webhook_id]\n",
        "\n",
        "        # Save the updated dictionary back to the JSON file\n",
        "        with open(json_file, \"w\") as f:\n",
        "            json.dump(webhooks_dict, f, indent=4)\n",
        "\n",
        "    await bot.tree.sync()\n",
        "\n",
        "# STEP 5: MAIN ENTRY POINT\n",
        "async def main() -> None:\n",
        "    await bot.start(TOKEN)\n",
        "\n",
        "# To run in a cloud service like Google Colab, Kaggle, etc.\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-BnerK4Yxi7"
      },
      "source": [
        "For viewing /editing the chat_history\n",
        "\n",
        "\n",
        "1. Enter the user/channel id(\"\"THE FULLPATH IS BASED ON THE DEFAULT BEHAVIOUR OF THE PROGRAM, IF YOU HAVE CHANGED IT THEN CHANGE THE FILE  PATH ACCORDINGLY**)\n",
        "2. Open the file using the fullpath\n",
        "3. Run the Styling cell\n",
        "4. Print the chat history by running the \"print_chat_history_nicely(chat_history)\"\n",
        "You can view all the messages in this window You can see some numbers associated with them.\n",
        "5. To modify a message enter the number associated with the message you want to modify.\n",
        "A text box will appear where you can entre your new message and click on \"sumbit\" when done. (The new message would be visible in the new window that was created)\n",
        "6. Now run the cell [Save back the chat history] and a message will tell your history is saved succesfully\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI0zm0tDyfqT"
      },
      "outputs": [],
      "source": [
        "#@title Type the user/channel id\n",
        "id = 1264073938175004757 # @param {type:\"integer\"}\n",
        "bot_id = \"\" # @param {type:\"string\"} #for the main bot the bot_id = is main_bot_\n",
        "fullpath = f\"/content/drive/MyDrive/Discord_bot/{id}_chat_history.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7QGNd7BYskF"
      },
      "outputs": [],
      "source": [
        "#@title Opens the chat history\n",
        "with open(fullpath, 'rb') as file:\n",
        "    chat_history = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4SZP1Oxm4y84"
      },
      "outputs": [],
      "source": [
        "# @title Styling\n",
        "\"\"\"from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "import json\"\"\"\n",
        "\n",
        "# Define the custom CSS once\n",
        "custom_css = \"\"\"\n",
        "<style>\n",
        "  .chat-container {\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    width: 100%;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "    background-color: #000000;\n",
        "    margin-top: 10px;\n",
        "    box-sizing: border-box;\n",
        "  }\n",
        "\n",
        "  .chat-message {\n",
        "    display: flex;\n",
        "    align-items: flex-start;\n",
        "    margin-bottom: 5px;\n",
        "    border-bottom: 1px solid #FFFFFF;\n",
        "    width: 100%;\n",
        "    box-sizing: border-box;\n",
        "  }\n",
        "\n",
        "  .message-serial {\n",
        "    font-weight: bold;\n",
        "    margin-right: 5px;\n",
        "    width: 30px;\n",
        "    flex-shrink: 0;\n",
        "  }\n",
        "\n",
        "  .message-role {\n",
        "    font-weight: bold;\n",
        "    margin-right: 5px;\n",
        "    width: 80px;\n",
        "    flex-shrink: 0;\n",
        "  }\n",
        "\n",
        "  .message-text {\n",
        "    flex: 1;\n",
        "    word-wrap: break-word;\n",
        "    white-space: pre-wrap;\n",
        "  }\n",
        "\n",
        "  .auto-resize-textarea {\n",
        "    resize: none;\n",
        "    overflow-y: hidden;\n",
        "    min-height: 50px;\n",
        "    max-height: 300px;\n",
        "  }\n",
        "</style>\n",
        "\n",
        "<script>\n",
        "function autoResize(textarea) {\n",
        "    textarea.style.height = 'auto';\n",
        "    textarea.style.height = textarea.scrollHeight + 'px';\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def apply_custom_css():\n",
        "    \"\"\"Applies the custom CSS and JavaScript.\"\"\"\n",
        "    display(HTML(custom_css))\n",
        "\n",
        "def print_chat_history_nicely(chat_history):\n",
        "    \"\"\"Prints chat history using Colab widgets and custom CSS for enhanced formatting,\n",
        "    including serial numbers for each message.\n",
        "\n",
        "    Args:\n",
        "      chat_history: A list of content objects representing the chat history.\n",
        "    \"\"\"\n",
        "    clear_output(wait=True)\n",
        "    apply_custom_css()\n",
        "\n",
        "    chat_container_html = \"<div class='chat-container'>\"\n",
        "\n",
        "    message_count = 0\n",
        "    for content_obj in chat_history:\n",
        "        if isinstance(content_obj, content.Content):\n",
        "            message_role = content_obj.role\n",
        "            text_content = content_obj.parts[0].text\n",
        "\n",
        "            chat_container_html += f\"\"\"\n",
        "            <div class=\"chat-message\">\n",
        "              <span class=\"message-serial\">{message_count}. </span>\n",
        "              <span class=\"message-role\">{message_role}:</span>\n",
        "              <span class=\"message-text\">{text_content}</span>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            message_count += 1\n",
        "        else:\n",
        "            print(\"Unexpected content type found in chat history.\")\n",
        "\n",
        "    chat_container_html += \"</div>\"\n",
        "    display(HTML(chat_container_html))\n",
        "\n",
        "    print(\"Finished printing chat history.\")\n",
        "\n",
        "def display_and_replace_message(content_obj):\n",
        "    \"\"\"Displays a selected chat message, takes user input, and replaces the message with the input.\n",
        "    Also includes a button to copy the displayed message.\n",
        "\n",
        "    Args:\n",
        "        content_obj: A content object representing a single chat message.\n",
        "    \"\"\"\n",
        "    if isinstance(content_obj, content.Content):\n",
        "        text_content = content_obj.parts[0].text\n",
        "        message_role = content_obj.role\n",
        "\n",
        "        input_text = widgets.Textarea(\n",
        "            value='',\n",
        "            placeholder='Type your message here...',\n",
        "            description='New Message:',\n",
        "            layout=widgets.Layout(width='100%', min_height='50px')\n",
        "        )\n",
        "\n",
        "        submit_button = widgets.Button(description=\"Submit\")\n",
        "        copy_button = widgets.Button(description=\"Copy Message\")\n",
        "\n",
        "        def update_display():\n",
        "            clear_output(wait=True)\n",
        "            apply_custom_css()\n",
        "\n",
        "            message_element = f\"\"\"\n",
        "            <div class=\"chat-container\">\n",
        "              <div class=\"chat-message\" id=\"selected-message\">\n",
        "                <span class=\"message-role\">{message_role}:</span>\n",
        "                <span class=\"message-text\">{text_content}</span>\n",
        "              </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            display(HTML(message_element))\n",
        "            display(widgets.HBox([copy_button, submit_button]))\n",
        "            display(input_text)\n",
        "\n",
        "            # Add JavaScript to make the textarea auto-resize\n",
        "            display(HTML(\"\"\"\n",
        "            <script>\n",
        "            var textarea = document.querySelector('.widget-textarea textarea');\n",
        "            textarea.classList.add('auto-resize-textarea');\n",
        "            textarea.setAttribute('onInput', 'autoResize(this)');\n",
        "            </script>\n",
        "            \"\"\"))\n",
        "\n",
        "        def on_submit_button_clicked(b):\n",
        "            nonlocal text_content\n",
        "            new_text_content = input_text.value\n",
        "            content_obj.parts[0].text = new_text_content\n",
        "            text_content = new_text_content\n",
        "            update_display()\n",
        "\n",
        "        def on_copy_button_clicked(b):\n",
        "            js_code = f\"\"\"\n",
        "            var textarea = document.createElement('textarea');\n",
        "            textarea.value = {json.dumps(text_content)};\n",
        "            document.body.appendChild(textarea);\n",
        "            textarea.select();\n",
        "            document.execCommand('copy');\n",
        "            document.body.removeChild(textarea);\n",
        "            \"\"\"\n",
        "            display(HTML(f\"<script>{js_code}</script>\"))\n",
        "            print(\"Message copied to clipboard!\")\n",
        "\n",
        "        submit_button.on_click(on_submit_button_clicked)\n",
        "        copy_button.on_click(on_copy_button_clicked)\n",
        "        update_display()\n",
        "\n",
        "    else:\n",
        "        print(\"Unexpected content type at the specified index.\")\n",
        "\n",
        "# Example usage:\n",
        "# print_chat_history_nicely(chat_history)\n",
        "# display_and_replace_message(chat_history[specific_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6-y_t0T5WY_"
      },
      "outputs": [],
      "source": [
        "#@title Prints the chat history on the screen\n",
        "print_chat_history_nicely(chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f1609f4c1d3d421fa06e9175b7243235",
            "173a6a62dff548bebbe9636142fbefb8",
            "d70305828d654ccf9398f8d31571f120",
            "bfbea4a002244295ba3c1b97f5def551",
            "8d6448346a63472b8a7d6ba5d534cdf0",
            "1f3d298230924ed7831ec45c2bed862c",
            "33c92405cb8d44738a55bf92450ca5f5",
            "efe22b77594440909d90f6642e7ae921",
            "8c51bd888430468cb6acda151867a3bc",
            "7fc23deeb0fd4ee2907042ec5a44169c",
            "606cc7cadb7141369b3e2c82b0e544ff"
          ]
        },
        "id": "OENDCqUg5XH_",
        "outputId": "bd4de0a1-f018-4457-e799-8a77830d3673"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  .chat-container {\n",
              "    display: flex;\n",
              "    flex-direction: column;\n",
              "    width: 100%;\n",
              "    padding: 10px;\n",
              "    border-radius: 5px;\n",
              "    background-color: #000000;\n",
              "    margin-top: 10px;\n",
              "    box-sizing: border-box;\n",
              "  }\n",
              "\n",
              "  .chat-message {\n",
              "    display: flex;\n",
              "    align-items: flex-start;\n",
              "    margin-bottom: 5px;\n",
              "    border-bottom: 1px solid #FFFFFF;\n",
              "    width: 100%;\n",
              "    box-sizing: border-box;\n",
              "  }\n",
              "\n",
              "  .message-serial {\n",
              "    font-weight: bold;\n",
              "    margin-right: 5px;\n",
              "    width: 30px;\n",
              "    flex-shrink: 0;\n",
              "  }\n",
              "\n",
              "  .message-role {\n",
              "    font-weight: bold;\n",
              "    margin-right: 5px;\n",
              "    width: 80px;\n",
              "    flex-shrink: 0;\n",
              "  }\n",
              "\n",
              "  .message-text {\n",
              "    flex: 1;\n",
              "    word-wrap: break-word;\n",
              "    white-space: pre-wrap;\n",
              "  }\n",
              "\n",
              "  .auto-resize-textarea {\n",
              "    resize: none;\n",
              "    overflow-y: hidden;\n",
              "    min-height: 50px;\n",
              "    max-height: 300px;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "<script>\n",
              "function autoResize(textarea) {\n",
              "    textarea.style.height = 'auto';\n",
              "    textarea.style.height = textarea.scrollHeight + 'px';\n",
              "}\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div class=\"chat-container\">\n",
              "              <div class=\"chat-message\" id=\"selected-message\">\n",
              "                <span class=\"message-role\">user:</span>\n",
              "                <span class=\"message-text\">Red</span>\n",
              "              </div>\n",
              "            </div>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1609f4c1d3d421fa06e9175b7243235",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(Button(description='Copy Message', style=ButtonStyle()), Button(description='Submit', style=But‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c51bd888430468cb6acda151867a3bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Textarea(value='Red', description='New Message:', layout=Layout(min_height='50px', width='100%'), placeholder=‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <script>\n",
              "            var textarea = document.querySelector('.widget-textarea textarea');\n",
              "            textarea.classList.add('auto-resize-textarea');\n",
              "            textarea.setAttribute('onInput', 'autoResize(this)');\n",
              "            </script>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown Replace message\n",
        "selected_message = 6 # @param {type:\"integer\"}\n",
        "display_and_replace_message(chat_history[selected_message])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HXJlAAY7NVE"
      },
      "source": [
        "##**Save back the chat history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2zSG2i25Zke",
        "outputId": "7bab011a-6a71-44dc-deeb-c2be03e16de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully updated the chat_history.pkl\n"
          ]
        }
      ],
      "source": [
        "with open(fullpath, 'wb') as file:\n",
        "    pickle.dump(chat_history, file)\n",
        "    print(\"Successfully updated the chat_history.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "173a6a62dff548bebbe9636142fbefb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Copy Message",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8d6448346a63472b8a7d6ba5d534cdf0",
            "style": "IPY_MODEL_1f3d298230924ed7831ec45c2bed862c",
            "tooltip": ""
          }
        },
        "1f3d298230924ed7831ec45c2bed862c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "33c92405cb8d44738a55bf92450ca5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606cc7cadb7141369b3e2c82b0e544ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fc23deeb0fd4ee2907042ec5a44169c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": "50px",
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8c51bd888430468cb6acda151867a3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextareaModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "New Message:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7fc23deeb0fd4ee2907042ec5a44169c",
            "placeholder": "Type your message here...",
            "rows": null,
            "style": "IPY_MODEL_606cc7cadb7141369b3e2c82b0e544ff",
            "value": "Red"
          }
        },
        "8d6448346a63472b8a7d6ba5d534cdf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbea4a002244295ba3c1b97f5def551": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70305828d654ccf9398f8d31571f120": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_33c92405cb8d44738a55bf92450ca5f5",
            "style": "IPY_MODEL_efe22b77594440909d90f6642e7ae921",
            "tooltip": ""
          }
        },
        "efe22b77594440909d90f6642e7ae921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f1609f4c1d3d421fa06e9175b7243235": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_173a6a62dff548bebbe9636142fbefb8",
              "IPY_MODEL_d70305828d654ccf9398f8d31571f120"
            ],
            "layout": "IPY_MODEL_bfbea4a002244295ba3c1b97f5def551"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}