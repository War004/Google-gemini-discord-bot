{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvBoob1J1HiZ"
      },
      "source": [
        "# Know Error\n",
        "游릴 The bot tends to genrate multiple responese for a single reply (fixed)\n",
        "\n",
        "游릴 Genrates multiple responses while working with media files (fixed)\n",
        "\n",
        "游릴 Is able to remember images only time it is uploaded.(fixed)\n",
        "\n",
        "游릴 Improving the video responses(Direct function added by google for video file)\n",
        "\n",
        "游릴 Finding a way to keep the converstion for the videos conversation\n",
        "\n",
        "游릴 If the user sends a gif through the inbuilt gif section, it's html page is downloaded.(fixed)\n",
        "\n",
        "[The gif is converted to a mp4 file. If your gif is shorter then it will treat it as a still photo as gemini sees videos with one frame per seconds, which might lead to wrong interpretation of the gif]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rJKqNdtYq1g"
      },
      "source": [
        "# Goal\n",
        "1. Fix the 2000 char limit. 九\n",
        "2. Saving the chats. 九\n",
        "3. Only reply when tagged or replied 九\n",
        "4. Consinent chats 九\n",
        "5. Image input 九\n",
        "6. Mutimedia input 九\n",
        "7. Webhook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "# d_bot\n",
        "This notebook lets you run a discord bot powered by google gemini api, with conversation memory which includes audio, video, and images.\n",
        "\n",
        "You can type **\"!check_token\"** to check how many tokens are being used.\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1OQGPc2CsYpnBhNfKEl0O0cDT6uXAcQ8g?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "nggWQnMA9EEl",
        "outputId": "de398a9c-34d3-4653-c476-907d39a9755b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then start block below (Uses only 13MB of data)</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title <b>v-- If you play on mobile, tap this to open music player and play the white noise to keep tab running in the background. or your session might get disconnected\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start block below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X69TeVJU4cmw",
        "outputId": "795b0f9e-8346-4d4d-a42a-add12b8597f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFKN43bICGME"
      },
      "source": [
        "# Step 1: Install requirments (Restart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma-s35dvLHdk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install Discord\n",
        "!pip install python-magic\n",
        "!pip install nest_asyncio\n",
        "!pip install moviepy\n",
        "!pip install textract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goraCIaRXzoe"
      },
      "source": [
        "Step 2: Get the api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5mUqu8_KXuzu"
      },
      "outputs": [],
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "C4BCsz3XX__W",
        "outputId": "93c173e6-f91c-4633-f7be-18acb7419b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-2m-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n",
            "Now select any one of the model and paste it in the 'model_name' below\n"
          ]
        }
      ],
      "source": [
        "# @title Step 2.5: List available models\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "print(\"Now select any one of the model and paste it in the 'model_name' below\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "wHUdpD-u1JAm"
      },
      "outputs": [],
      "source": [
        "# Set the event listener for the dropdown change\n",
        "# @title Model configuration\n",
        "text_generation_config = {\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "# Initial prompt\n",
        "system_instruction = \"When you the see the user message in the following format = ([string], [number]): {message content}. It means the conversation is happening a server in discord. The string represents the username of the of the user who have sent the message and the number is the user id of the user.  Multiple people can interact during this, make sure too act accordingly. If you don't see this format and just see this format = (number) it means they are talking to you in dm, so act accordingly. \" # @param {type:\"string\"}\n",
        "model_name = \"models/gemini-1.5-pro-latest\" # @param {type:\"string\"}\n",
        "\n",
        "# Create the model using the selected model name from the dropdown\n",
        "model = genai.GenerativeModel(model_name = model_name, generation_config=text_generation_config, system_instruction=system_instruction, safety_settings=safety_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oCPt1z07LaCw"
      },
      "outputs": [],
      "source": [
        "# @title Functions\n",
        "import time\n",
        "from random import choice, randint\n",
        "import os\n",
        "import requests\n",
        "import textract\n",
        "from urllib.parse import urlparse, unquote\n",
        "import re\n",
        "import cv2\n",
        "import shutil\n",
        "import mimetypes\n",
        "import magic\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "import moviepy.editor as mp\n",
        "\n",
        "def extract_text(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts text from a document\n",
        "    \"\"\"\n",
        "    # Extract text from the document\n",
        "    text = textract.process(file_path).decode('utf-8')\n",
        "\n",
        "    return text\n",
        "\n",
        "def upload_to_gemini(path, mime_type=None):\n",
        "    \"\"\"Uploads the given file to Gemini.\n",
        "\n",
        "    See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
        "    \"\"\"\n",
        "    file = genai.upload_file(path, mime_type=mime_type)\n",
        "    print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
        "    return file\n",
        "\n",
        "def wait_for_files_active(files):\n",
        "    \"\"\"Waits for the given files to be active.\n",
        "\n",
        "    Some files uploaded to the Gemini API need to be processed before they can be\n",
        "    used as prompt inputs. The status can be seen by querying the file's \"state\"\n",
        "    field.\n",
        "\n",
        "    This implementation uses a simple blocking polling loop. Production code\n",
        "    should probably employ a more sophisticated approach.\n",
        "    \"\"\"\n",
        "    print(\"Waiting for file processing...\")\n",
        "    for name in (file.name for file in files):\n",
        "      file = genai.get_file(name)\n",
        "      while file.state.name == \"PROCESSING\":\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(10)\n",
        "        file = genai.get_file(name)\n",
        "      if file.state.name != \"ACTIVE\":\n",
        "        raise Exception(f\"File {file.name} failed to process\")\n",
        "    print(\"...all files ready\")\n",
        "    print()\n",
        "\n",
        "def download_file(attachment_link: str, user_id: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Downloads the file, determines its type, and renames it with the correct extension. + handle gifs from tenor\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the URL to get the file name without the extension\n",
        "        parsed_link = urlparse(unquote(attachment_link))\n",
        "        path = parsed_link.path\n",
        "        original_filename = os.path.basename(path).split('?')[0]\n",
        "\n",
        "        # Create a temporary filename with the user_id as prefix and no extension\n",
        "        temp_filename = f'file_{user_id}'\n",
        "        temp_filename_no_ext = temp_filename.rsplit('.', 1)[0]\n",
        "\n",
        "        # Download the file\n",
        "        response = requests.get(attachment_link)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        # Save the file without an extension\n",
        "        with open(temp_filename_no_ext, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        print(f\"File downloaded successfully: {temp_filename_no_ext}\")\n",
        "\n",
        "        # Determine the file type and the correct extension\n",
        "        mime_type = determine_file_type(temp_filename_no_ext)\n",
        "        extension = mimetypes.guess_extension(mime_type) or '.bin'  # Default to .bin if unknown\n",
        "\n",
        "        # Check if the downloaded file is actually a GIF\n",
        "        if mime_type == 'text/html' and 'tenor.com' in parsed_link.netloc:\n",
        "            # If the file is HTML and from Tenor, extract the actual GIF URL from the HTML content\n",
        "            gif_url = extract_gif_url_from_html(temp_filename_no_ext)\n",
        "            if gif_url:\n",
        "                return download_file(gif_url, user_id)  # Recursively download the actual GIF\n",
        "            else:\n",
        "                raise ValueError(\"Unable to extract GIF URL from Tenor HTML\")\n",
        "\n",
        "        # Rename the file with the correct extension\n",
        "        final_filename = f'{temp_filename_no_ext}{extension}'\n",
        "        os.rename(temp_filename_no_ext, final_filename)\n",
        "        print(f\"File renamed to: {final_filename} with MIME type: {mime_type}\")\n",
        "\n",
        "        return mime_type, final_filename\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Failed to download file. Error: {e}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def determine_file_type(filepath: str) -> str:\n",
        "    \"\"\"\n",
        "    Determines the MIME type of a file by reading its contents.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize the magic library\n",
        "        mime = magic.Magic(mime=True)\n",
        "        mime_type = mime.from_file(filepath)\n",
        "        return mime_type\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine file type. Error: {e}\")\n",
        "        return 'application/octet-stream'\n",
        "\n",
        "\n",
        "# Function to load chat history from a file\n",
        "def load_chat_history(user_id, custom_file_path):\n",
        "    full_path = f'{custom_file_path}{user_id}_chat_history.pkl'\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        with open(full_path, 'wb') as file:\n",
        "            pickle.dump([], file)\n",
        "\n",
        "    # Open the file and load the chat history\n",
        "    with open(full_path, 'rb') as file:\n",
        "        chat_history = pickle.load(file)\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "\n",
        "# Function to save the chat history from a file\n",
        "def save_chat_history(user_id, chat, custom_file_path):\n",
        "    full_path = f'{custom_file_path}{user_id}_chat_history.pkl'\n",
        "    with open(full_path, 'wb') as file:\n",
        "        pickle.dump(chat.history, file)\n",
        "\n",
        "def save_filetwo(user_id, time_file_path, url):\n",
        "    file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "\n",
        "    # Ensure the file exists and contains a valid JSON list; if not, initialize it\n",
        "    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            data = []\n",
        "\n",
        "    # Append the new data\n",
        "    new_data = {\n",
        "        'file_uri': url,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    data.append(new_data)\n",
        "    print(file_path)\n",
        "\n",
        "    # Write the updated list back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "        print(\"Successful saved the file url and upload time\")\n",
        "#def check_chat_history(user_id, time_file_path):\n",
        "\n",
        "def check_expired_files(user_id, time_file_path, history):\n",
        "    tempoery = []\n",
        "    file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            data = []\n",
        "    current_time = datetime.utcnow()\n",
        "    expired_files = []\n",
        "\n",
        "    for entry in data:\n",
        "        upload_time = datetime.fromisoformat(entry['timestamp'])\n",
        "        if current_time - upload_time > timedelta(hours=48):\n",
        "            expired_files.append(entry)\n",
        "\n",
        "        for dct in expired_files:\n",
        "            tempoery.append(dct['file_uri'])\n",
        "        for link in tempoery:\n",
        "            target_word = (f'{link}')\n",
        "            chat_history = [entry for entry in history if target_word not in str(entry)]\n",
        "            print(f'Successfully removed: {target_word}')\n",
        "            file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "            with open(file_path, 'r') as file:\n",
        "                data = json.load(file)\n",
        "                data = [entry for entry in data if target_word not in str(entry)]\n",
        "            with open(file_path, 'w') as file:\n",
        "                json.dump(data, file, indent=4)\n",
        "                print(\"Successfully removed the file_uri\")\n",
        "\n",
        "\n",
        "    return history\n",
        "\n",
        "def extract_gif_url_from_html(html_filepath: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the actual GIF URL from an HTML file downloaded from Tenor.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(html_filepath, 'r', encoding='utf-8') as file:\n",
        "            html_content = file.read()\n",
        "\n",
        "        # Use regular expressions to find the GIF URL\n",
        "        gif_url_pattern = re.compile(r'https://media\\.tenor\\.com/[^\"]+\\.gif')\n",
        "        match = gif_url_pattern.search(html_content)\n",
        "\n",
        "        if match:\n",
        "            return match.group(0)\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract GIF URL from HTML. Error: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPR93kb1_mN8"
      },
      "source": [
        "# Running The Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYLAjggYGKVB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import aiohttp\n",
        "from typing import Final\n",
        "import os\n",
        "import discord\n",
        "from discord import Intents, Client, Message\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import nest_asyncio\n",
        "\n",
        "# STEP 0: LOAD OUR TOKEN FROM SOMEWHERE SAFE\n",
        "TOKEN: Final[str] = userdata.get('DISCORD_TOKEN')\n",
        "\n",
        "# STEP 1: BOT SETUP\n",
        "intents: Intents = Intents.default()\n",
        "intents.message_content = True\n",
        "client: Client = Client(intents=intents)\n",
        "processing_messages = {}\n",
        "\n",
        "# STEP 2: MESSAGE FUNCTIONALITY\n",
        "async def send_message(message: Message, response: str, id_str: str) -> None:\n",
        "    if len(response) <= 2000:\n",
        "        await message.channel.send(response)\n",
        "    else:\n",
        "        start_index = 0\n",
        "        while start_index < len(response):\n",
        "            end_index = response.rfind(' ', start_index, start_index + 2000)\n",
        "            if end_index == -1:\n",
        "                end_index = start_index + 2000\n",
        "            chunk = response[start_index:end_index]\n",
        "            await message.channel.send(chunk)\n",
        "            start_index = end_index + 1\n",
        "\n",
        "\"\"\"def process_messages(messages_combined: str) -> str:\n",
        "    return f\"Processed summary of messages: {messages_combined}\"\n",
        "    \"\"\"\n",
        "\n",
        "@client.event\n",
        "async def on_message(message: Message) -> None:\n",
        "    global chat_history, history\n",
        "    if message.author == client.user:\n",
        "        return\n",
        "\n",
        "    is_dm = isinstance(message.channel, discord.DMChannel)\n",
        "    id_str = str(message.author.id) if is_dm else str(message.channel.id)\n",
        "\n",
        "    bot_mentioned = client.user in message.mentions\n",
        "    is_reply = message.reference is not None and message.reference.resolved.author == client.user\n",
        "\n",
        "    if is_reply and not is_dm and id_str in processing_messages:\n",
        "        await message.channel.send(f\"<@{(message.author.id)}> 丘멆잺 The bot is currently processing another request. Please wait a moment.\")\n",
        "        return\n",
        "\n",
        "    #the summary function need more work...\n",
        "    \"\"\"if message.content.startswith(\"!summary:\"):\n",
        "        system_instruction = \"You are now, meant to summaries a bunch off text. Act like a you are in a third person view and summaries what is happening in the chat in a concise manner with proper timestamps.[Don't try to mention anyone] \"\n",
        "        model = genai.GenerativeModel(model_name = model_name, generation_config=text_generation_config, system_instruction=system_instruction, safety_settings=safety_settings)\n",
        "        try:\n",
        "            num_messages = int(message.content.split(\":\")[1].strip())\n",
        "            if num_messages <= 0:\n",
        "                await message.channel.send(\"丘멆잺 Please provide a positive number of messages.\")\n",
        "                return\n",
        "        except ValueError:\n",
        "            await message.channel.send(\"丘멆잺 Please provide a valid number of messages.\")\n",
        "            return\n",
        "\n",
        "        await message.add_reaction('游댮')\n",
        "        processing_messages[id_str] = message.id\n",
        "\n",
        "        try:\n",
        "            messages = []\n",
        "            async for msg in message.channel.history(limit=num_messages):\n",
        "                messages.append(msg)\n",
        "            messages_content = [f\"{msg.created_at.strftime('%Y-%m-%d %H:%M:%S')} - {msg.author}: {msg.content}\" for msg in messages if msg.content]\n",
        "            messages_combined = \"\\n\".join(messages_content) #getting all the messages only supports text\n",
        "\n",
        "            # Replace this with your processing function\n",
        "            chat = model.start_chat(history=[])\n",
        "            summary = chat.send_message(messages_combined)\n",
        "            summary = summary.text\n",
        "\n",
        "            await send_message(message, summary, id_str)\n",
        "        finally:\n",
        "            processing_message_id = processing_messages.pop(id_str, None)\n",
        "            if processing_message_id:\n",
        "                processing_message = await message.channel.fetch_message(processing_message_id)\n",
        "                await processing_message.remove_reaction('游댮', client.user)\n",
        "        return\"\"\"\n",
        "\n",
        "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
        "    urls = url_pattern.findall(message.content)\n",
        "    Direct_upload = False\n",
        "    Link_upload = False\n",
        "    attach_url = None\n",
        "    custom_path = '/content/drive/MyDrive/Discord_bot/'\n",
        "    time_file_path = '/content/drive/MyDrive/Discord_bot/Time_files/'\n",
        "    tempoery = []\n",
        "\n",
        "\n",
        "    if message.content.strip() == \"!check_token\":\n",
        "        history = load_chat_history(id_str, custom_path)\n",
        "        chat_history = check_expired_files(id_str, time_file_path, history)\n",
        "        chat = model.start_chat(history=chat_history)\n",
        "        response = f\"{model.count_tokens(chat.history)}\"\n",
        "        await send_message(message, response, id_str)\n",
        "        return\n",
        "\n",
        "    if bot_mentioned or is_reply or is_dm:\n",
        "        username: str = str(message.author)\n",
        "        if not is_dm:\n",
        "            message.content = f\"({username},[{message.author.id}]): {message.content}\"\n",
        "\n",
        "        if urls:\n",
        "            attach_url = urls[0]\n",
        "            Link_upload = True\n",
        "\n",
        "        if message.attachments:\n",
        "            for attachment in message.attachments:\n",
        "                attach_url = attachment.url\n",
        "                Direct_upload = True\n",
        "                break\n",
        "\n",
        "        print(f\"({id_str}): {message.content}\")\n",
        "        history = load_chat_history(id_str, custom_path)\n",
        "        chat_history = check_expired_files(id_str, time_file_path, history)\n",
        "        chat = model.start_chat(history=chat_history)\n",
        "\n",
        "        # Add a :red_circle: reaction to indicate processing\n",
        "        processing_messages[id_str] = message.id\n",
        "        await message.add_reaction('游댮')\n",
        "\n",
        "        try:\n",
        "            chat = model.start_chat(history=chat_history)\n",
        "\n",
        "            if Direct_upload or Link_upload:\n",
        "                format, downloaded_file = download_file(attach_url, id_str)\n",
        "\n",
        "                if format in ('application/pdf', 'application/txt'):\n",
        "                    text = extract_text(downloaded_file)\n",
        "                    message.content = f'The user has uploaded a document: {text} The document has ended!! The current user input is: {message.content}'\n",
        "\n",
        "                    response = chat.send_message(message.content)\n",
        "                    response = response.text\n",
        "\n",
        "                    save_chat_history(id_str, chat, custom_path)\n",
        "                    await send_message(message, response, id_str)\n",
        "                    print(f\"Bot: {response}\")\n",
        "\n",
        "                else:\n",
        "                    if format in ('image/gif'):\n",
        "                        gif_clip = mp.VideoFileClip(downloaded_file)\n",
        "                        output_path = f\"{downloaded_file.rsplit('.', 1)[0]}.mp4\"\n",
        "                        gif_clip.write_videofile(output_path, codec='libx264')\n",
        "                        downloaded_file = output_path\n",
        "                        format = 'video/mp4'\n",
        "\n",
        "                    media_file = [upload_to_gemini(f\"{downloaded_file}\", mime_type= f\"{format}\"),]\n",
        "\n",
        "                    wait_for_files_active(media_file) # Some files have a processing delay. Wait for them to be ready.\n",
        "\n",
        "                    save_filetwo(id_str, time_file_path, media_file[0].uri)\n",
        "\n",
        "                    response = chat.send_message([message.content, media_file[0]])\n",
        "                    response = response.text\n",
        "\n",
        "                    save_chat_history(id_str, chat, custom_path)\n",
        "                    await send_message(message, response, id_str)\n",
        "                    print(f\"Bot: {response}\")\n",
        "                Direct_upload = False\n",
        "                Link_upload = False\n",
        "\n",
        "            else:\n",
        "                response = chat.send_message(message.content)\n",
        "                response = response.text\n",
        "\n",
        "                save_chat_history(id_str, chat, custom_path)\n",
        "                await send_message(message, response, id_str)\n",
        "                print(f\"Bot: {response}\")\n",
        "\n",
        "        finally:\n",
        "            # Remove the :red_circle: reaction to indicate processing is done\n",
        "            processing_message_id = processing_messages.pop(id_str, None)\n",
        "            if processing_message_id:\n",
        "                processing_message = await message.channel.fetch_message(processing_message_id)\n",
        "                await processing_message.remove_reaction('游댮', client.user)\n",
        "\n",
        "# STEP 5: MAIN ENTRY POINT\n",
        "async def main() -> None:\n",
        "    await client.start(TOKEN)\n",
        "\n",
        "# To run in a cloud service like Google Colab, Kaggle, etc.\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Run the main function\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-BnerK4Yxi7"
      },
      "source": [
        "(For debugging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4phZmYoYsWN"
      },
      "outputs": [],
      "source": [
        "fullpath = '/content/drive/MyDrive/Discord_bot/738618866699075595_chat_history.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7QGNd7BYskF"
      },
      "outputs": [],
      "source": [
        "with open(fullpath, 'rb') as file:\n",
        "    chat_history = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvTMbGENYswd"
      },
      "outputs": [],
      "source": [
        "print(chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txG8dqFGY1kj"
      },
      "outputs": [],
      "source": [
        "print(chat_history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
