{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvBoob1J1HiZ"
      },
      "source": [
        "# Know Error\n",
        "🟩 The bot tends to genrate multiple responese for a single reply (fixed)\n",
        "\n",
        "🟩 Genrates multiple responses while working with media files (fixed)\n",
        "\n",
        "🟩 Is able to remember images only time it is uploaded.(fixed)\n",
        "\n",
        "🟩 Improving the video responses(Direct function added by google for video file)\n",
        "\n",
        "🟩 Finding a way to keep the converstion for the videos conversation\n",
        "\n",
        "🟨 If the user sends a gif through the inbuilt gif section, it's html page is downloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rJKqNdtYq1g"
      },
      "source": [
        "# Goal\n",
        "1. Fix the 2000 char limit. ✅\n",
        "2. Saving the chats. ✅\n",
        "3. Only reply when tagged or replied ✅\n",
        "4. Consinent chats ✅\n",
        "5. Image input ✅\n",
        "6. Mutimedia input ✅\n",
        "7. Webhook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "# d_bot\n",
        "This notebook lets you run a discord bot powered by google gemini api, with conversation memory which includes audio, video, and images.\n",
        "\n",
        "You can type **\"!check_token\"** to check how many tokens are being used.\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1OQGPc2CsYpnBhNfKEl0O0cDT6uXAcQ8g?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "nggWQnMA9EEl",
        "outputId": "de398a9c-34d3-4653-c476-907d39a9755b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<b>Press play on the music player to keep the tab alive, then start block below (Uses only 13MB of data)</b><br/>\n",
              "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title <b>v-- If you play on mobile, tap this to open music player and play the white noise to keep tab running in the background. or your session might get disconnected\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start block below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X69TeVJU4cmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2d515b-a42f-493d-f63f-d283dfbbd39d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFKN43bICGME"
      },
      "source": [
        "# Step 1: Install requirments (Restart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma-s35dvLHdk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install Discord\n",
        "!pip install python-magic\n",
        "!pip install nest_asyncio\n",
        "!pip install textract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Get the api key"
      ],
      "metadata": {
        "id": "goraCIaRXzoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "5mUqu8_KXuzu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2.5: List available models\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "print(\"Now select any one of the model and paste it in the 'model_name' below\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "C4BCsz3XX__W",
        "outputId": "ce02c727-ad74-4798-a9c9-ec943810f1e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n",
            "Now select any one of the model and paste it in the 'model_name' below\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the event listener for the dropdown change\n",
        "# @title Model configuration\n",
        "text_generation_config = {\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "# Initial prompt\n",
        "system_instruction = \".\" # @param {type:\"string\"}\n",
        "model_name = \"models/gemini-1.5-pro-latest\" # @param {type:\"string\"}\n",
        "\n",
        "# Create the model using the selected model name from the dropdown\n",
        "model = genai.GenerativeModel(model_name = model_name, generation_config=text_generation_config, system_instruction=system_instruction, safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "wHUdpD-u1JAm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oCPt1z07LaCw"
      },
      "outputs": [],
      "source": [
        "# @title Functions\n",
        "\n",
        "from random import choice, randint\n",
        "import os\n",
        "import requests\n",
        "import textract\n",
        "from urllib.parse import urlparse, unquote\n",
        "import re\n",
        "import cv2\n",
        "import shutil\n",
        "import mimetypes\n",
        "import magic\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def extract_text(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts text from a document\n",
        "    \"\"\"\n",
        "    # Extract text from the document\n",
        "    text = textract.process(file_path).decode('utf-8')\n",
        "\n",
        "    return text\n",
        "\n",
        "def download_file(attachment_link: str, user_id: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Downloads the file, determines its type, and renames it with the correct extension.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the URL to get the file name without the extension\n",
        "        parsed_link = urlparse(unquote(attachment_link))\n",
        "        path = parsed_link.path\n",
        "        original_filename = os.path.basename(path).split('?')[0]\n",
        "\n",
        "        # Create a temporary filename with the user_id as prefix and no extension\n",
        "        temp_filename = f'file_{user_id}'\n",
        "        temp_filename_no_ext = temp_filename.rsplit('.', 1)[0]\n",
        "\n",
        "        # Download the file\n",
        "        response = requests.get(attachment_link)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        # Save the file without an extension\n",
        "        with open(temp_filename_no_ext, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        print(f\"File downloaded successfully: {temp_filename_no_ext}\")\n",
        "\n",
        "        # Determine the file type and the correct extension\n",
        "        mime_type = determine_file_type(temp_filename_no_ext)\n",
        "        extension = mimetypes.guess_extension(mime_type) or '.bin'  # Default to .bin if unknown\n",
        "\n",
        "        # Rename the file with the correct extension\n",
        "        final_filename = f'{temp_filename_no_ext}{extension}'\n",
        "        os.rename(temp_filename_no_ext, final_filename)\n",
        "        print(f\"File renamed to: {final_filename} with MIME type: {mime_type}\")\n",
        "\n",
        "        return extension, final_filename\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Failed to download file. Error: {e}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def determine_file_type(filepath: str) -> str:\n",
        "    \"\"\"\n",
        "    Determines the MIME type of a file by reading its contents.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize the magic library\n",
        "        mime = magic.Magic(mime=True)\n",
        "        mime_type = mime.from_file(filepath)\n",
        "        return mime_type\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine file type. Error: {e}\")\n",
        "        return 'application/octet-stream'\n",
        "\n",
        "\n",
        "# Function to load chat history from a file\n",
        "def load_chat_history(user_id, custom_file_path):\n",
        "    full_path = f'{custom_file_path}{user_id}_chat_history.pkl'\n",
        "\n",
        "    if not os.path.exists(full_path):\n",
        "        with open(full_path, 'wb') as file:\n",
        "            pickle.dump([], file)\n",
        "\n",
        "    # Open the file and load the chat history\n",
        "    with open(full_path, 'rb') as file:\n",
        "        chat_history = pickle.load(file)\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "\n",
        "# Function to save the chat history from a file\n",
        "def save_chat_history(user_id, chat, custom_file_path):\n",
        "    full_path = f'{custom_file_path}{user_id}_chat_history.pkl'\n",
        "    with open(full_path, 'wb') as file:\n",
        "        pickle.dump(chat.history, file)\n",
        "\n",
        "def save_filetwo(user_id, time_file_path, url):\n",
        "    file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "\n",
        "    # Ensure the file exists and contains a valid JSON list; if not, initialize it\n",
        "    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            data = []\n",
        "\n",
        "    # Append the new data\n",
        "    new_data = {\n",
        "        'file_uri': url,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    data.append(new_data)\n",
        "    print(file_path)\n",
        "\n",
        "    # Write the updated list back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "        print(\"Successful saved the file url and upload time\")\n",
        "\n",
        "def check_expired_files(user_id, time_file_path):\n",
        "    #check if the url is expired\n",
        "    file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        try:\n",
        "            data = json.load(file)\n",
        "        except json.JSONDecodeError:\n",
        "            data = []\n",
        "    current_time = datetime.utcnow()\n",
        "    expired_files = []\n",
        "\n",
        "    for entry in data:\n",
        "        upload_time = datetime.fromisoformat(entry['timestamp'])\n",
        "        if current_time - upload_time > timedelta(hours=48):\n",
        "            expired_files.append(entry)\n",
        "\n",
        "    return expired_files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPR93kb1_mN8"
      },
      "source": [
        "# Running The Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYLAjggYGKVB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import aiohttp\n",
        "from typing import Final\n",
        "import os\n",
        "import discord\n",
        "from discord import Intents, Client, Message\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import nest_asyncio\n",
        "\n",
        "# STEP 0: LOAD OUR TOKEN FROM SOMEWHERE SAFE\n",
        "TOKEN: Final[str] = userdata.get('DISCORD_TOKEN')\n",
        "\n",
        "# STEP 1: BOT SETUP\n",
        "intents: Intents = Intents.default()\n",
        "intents.message_content = True\n",
        "client: Client = Client(intents=intents)\n",
        "\n",
        "# STEP 2: MESSAGE FUNCTIONALITY\n",
        "async def send_message(message: Message, response: str, user_id: str) -> None:\n",
        "    # Check if the entire response is within the Discord character limit\n",
        "    if len(response) <= 2000:\n",
        "        await message.channel.send(response)\n",
        "    else:\n",
        "        # Initialize the start index of the chunk\n",
        "        start_index = 0\n",
        "        while start_index < len(response):\n",
        "            # Find the end index by looking for the last space before the 2000 character limit\n",
        "            end_index = response.rfind(' ', start_index, start_index + 2000)\n",
        "            # If no space is found, just cut at the 2000 character limit\n",
        "            if end_index == -1:\n",
        "                end_index = start_index + 2000\n",
        "            # Extract the chunk of text\n",
        "            chunk = response[start_index:end_index]\n",
        "            # Send the chunk as a separate message to the channel\n",
        "            await message.channel.send(chunk)\n",
        "            # Update the start index to the end of the last chunk\n",
        "            start_index = end_index + 1  # Skip the space\n",
        "\n",
        "# STEP 3: HANDLING THE STARTUP FOR OUR BOT\n",
        "@client.event\n",
        "async def on_message(message: Message) -> None:\n",
        "    # Ignore messages sent by the bot itself\n",
        "    if message.author == client.user:\n",
        "        return\n",
        "\n",
        "    # Check if the message is in a DM channel\n",
        "    is_dm = isinstance(message.channel, discord.DMChannel)\n",
        "\n",
        "    # Check if the bot is mentioned or if the message is a reply to the bot\n",
        "    bot_mentioned = client.user in message.mentions\n",
        "    is_reply = message.reference is not None and message.reference.resolved.author == client.user\n",
        "\n",
        "    # Regular expression to detect URLs\n",
        "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
        "    urls = url_pattern.findall(message.content)\n",
        "    Direct_upload = False\n",
        "    Link_upload = False\n",
        "    attach_url = None\n",
        "    custom_path = '/content/drive/MyDrive/Discord_bot/'\n",
        "    time_file_path = '/content/drive/MyDrive/Discord_bot/Time_files/'\n",
        "    tempoery = []\n",
        "\n",
        "    # Handle !check_token command\n",
        "    if message.content.strip() == \"!check_token\":\n",
        "        user_id: str = str(message.author.id)  # Get the user's ID as a string\n",
        "        chat_history = load_chat_history(user_id, custom_path)\n",
        "        no_files = check_expired_files(user_id, time_file_path)\n",
        "        #extracting the expried urls\n",
        "        for dct in no_files:\n",
        "            tempoery.append(dct['file_uri'])\n",
        "        for link in tempoery:\n",
        "            target_word = (f'{link}')\n",
        "            chat_history = [entry for entry in chat_history if target_word not in str(entry)]\n",
        "            print(f'Succesfully removed: {target_word}')\n",
        "            file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "            with open(file_path, 'r') as file:\n",
        "\n",
        "                data = json.load(file)\n",
        "                for entry in data:\n",
        "                    data = [entry for entry in data if target_word not in str(entry)]\n",
        "\n",
        "            with open(file_path, 'w') as file:\n",
        "                #updateing the url file\n",
        "                json.dump(data, file, indent=4)\n",
        "                print(\"Successful removed the file_uri\")\n",
        "        chat = model.start_chat(history=chat_history)\n",
        "        #token_count = model.count_tokens(chat.history)\n",
        "        response = f\"{model.count_tokens(chat.history)}\"\n",
        "        await send_message(message, response, user_id)\n",
        "        return\n",
        "\n",
        "    # Respond only if the bot is mentioned, if it's a reply to the bot's message, if a URL is detected,\n",
        "    # or if the message is in a DM channel\n",
        "    if bot_mentioned or is_reply or is_dm:\n",
        "        user_id: str = str(message.author.id)  # Get the user's ID as a string\n",
        "        username: str = str(message.author)\n",
        "        channel: str = str(message.channel)\n",
        "\n",
        "        # Check for attachments in the message\n",
        "        if urls:\n",
        "            attach_url = urls[0]\n",
        "            Link_upload = True\n",
        "\n",
        "        if message.attachments:\n",
        "            for attachment in message.attachments:\n",
        "                attach_url = attachment.url\n",
        "                Direct_upload = True\n",
        "                break\n",
        "\n",
        "\n",
        "        #Loading the chat history\n",
        "        print(f\"({user_id}): {message.content}\")\n",
        "        chat_history = load_chat_history(user_id, custom_path)\n",
        "        no_files = check_expired_files(user_id, time_file_path)\n",
        "        for dct in no_files:\n",
        "              tempoery.append(dct['file_uri'])\n",
        "        for link in tempoery:\n",
        "            target_word = (f'{link}')\n",
        "            chat_history = [entry for entry in chat_history if target_word not in str(entry)]\n",
        "            print(f'Succesfully removed: {target_word}')\n",
        "            file_path = f'{time_file_path}{user_id}_files_metadata.json'\n",
        "            with open(file_path, 'r') as file:\n",
        "\n",
        "                data = json.load(file)\n",
        "                for entry in data:\n",
        "                    data = [entry for entry in data if target_word not in str(entry)]\n",
        "\n",
        "            with open(file_path, 'w') as file:\n",
        "                json.dump(data, file, indent=4)\n",
        "                print(\"Successful removed the file_uri\")\n",
        "\n",
        "\n",
        "        chat = model.start_chat(history=chat_history)\n",
        "\n",
        "        if Direct_upload or Link_upload:\n",
        "            format, downloaded_file = download_file(attach_url, user_id)\n",
        "\n",
        "\n",
        "            # Downloading/extracting text from the file while returning the file type\n",
        "            if format in ('.pdf', '.docx', '.txt'):\n",
        "                text = extract_text(downloaded_file)\n",
        "                message.content = f'The user has uploaded a document: {text} The document has ended!! The current user input is: {message.content}'\n",
        "\n",
        "                response = chat.send_message(message.content)\n",
        "                response = response.text\n",
        "\n",
        "                save_chat_history(user_id, chat, custom_path)\n",
        "                await send_message(message, response, user_id)\n",
        "                print(f\"Bot: {response}\")\n",
        "\n",
        "            else:\n",
        "                media_file = genai.upload_file(path=downloaded_file)\n",
        "                save_filetwo(user_id, time_file_path, media_file.uri)\n",
        "\n",
        "                response = chat.send_message([message.content, media_file])\n",
        "                response = response.text\n",
        "\n",
        "                save_chat_history(user_id, chat, custom_path)\n",
        "                await send_message(message, response, user_id)\n",
        "                print(f\"Bot: {response}\")\n",
        "            Direct_upload = False\n",
        "            Link_upload = False\n",
        "\n",
        "        else:\n",
        "            response = chat.send_message(message.content)\n",
        "            response = response.text\n",
        "\n",
        "            save_chat_history(user_id, chat, custom_path)\n",
        "            await send_message(message, response, user_id)\n",
        "            print(f\"Bot: {response}\")\n",
        "\n",
        "# STEP 5: MAIN ENTRY POINT\n",
        "async def main() -> None:\n",
        "    await client.start(TOKEN)\n",
        "\n",
        "# To run in a cloud service like Google Colab, Kaggle, etc.\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Run the main function\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(For debugging)"
      ],
      "metadata": {
        "id": "V-BnerK4Yxi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fullpath = '/content/drive/MyDrive/Discord_bot/738618866699075595_chat_history.pkl'"
      ],
      "metadata": {
        "id": "e4phZmYoYsWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(fullpath, 'rb') as file:\n",
        "    chat_history = pickle.load(file)"
      ],
      "metadata": {
        "id": "B7QGNd7BYskF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_history)"
      ],
      "metadata": {
        "id": "dvTMbGENYswd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_history)"
      ],
      "metadata": {
        "id": "txG8dqFGY1kj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}